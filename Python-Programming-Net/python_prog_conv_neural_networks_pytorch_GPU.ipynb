{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv neural network w/ pytorch and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pythonprogramming.net/introduction-deep-learning-neural-network-pytorch/\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# notebook for lab instead of tqdm which is more for terminal apps; still having issues though\n",
    "# https://pypi.org/project/tqdm/#ipython-jupyter-integration\n",
    "# https://tqdm.github.io/docs/notebook/\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use(\"ggplot\")\n",
    "\n",
    "model_name = \"model-X\"  # grab whatever model you want to end up plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA = False  # set to True for 1st run\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"kagglecatsanddogs_3367a/PetImages/Cat\"\n",
    "    DOGS = \"kagglecatsanddogs_3367a/PetImages/Dog\"\n",
    "    TESTING = \"kagglecatsanddogs_3367a/PetImages/Testing\"\n",
    "    LABELS = {CATS:0, DOGS:1}\n",
    "    training_data = []\n",
    "    \n",
    "    # use as counter while appending data, use to check for balance\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        # iterate over directories, which were given in full by the LABELS dictionary\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            # get the file by iterating though all the files in that label's directory (listdir lists all files)\n",
    "            # tqdm shows progress bar\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                # some files are not jpg images\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)  # get full path for the file\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # grayscale to make simpler for neural net\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        # np.eye creates identity matrix, taking the ith row of the matrix is like one hot encoding\n",
    "                        self.training_data.append([np.array(img), np.eye(len(LABELS))[self.LABELS[label]]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    # if images have issues\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        # print(str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats:\", self.catcount)\n",
    "        print(\"Dogs:\", self.dogcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # just run the init of parent class (nn.Module) https://realpython.com/python-super/\n",
    "        # these are 2d layers but pytorch can take any dimensions\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)  # input is 1 image, 32 output channels 5 is the kernel size\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)  # based on 1st layer, then we decide output gets 64 channels\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        \n",
    "        x = torch.randn(50, 50).view(-1, 1, 50, 50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        # old version of pytorch didn't have flatten function\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)  # need to get the right size for input\n",
    "        self.fc2 = nn.Linear(512, 2)  # 2 classes of cats and dogs\n",
    "    \n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # shape of pooling is 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        \n",
    "        # print(x[0].shape) # returns torch.Size([128, 2, 2])\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]  # set the input if not already done \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)  # x is a batch of x's,  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the CPU\n"
     ]
    }
   ],
   "source": [
    "# tensors on GPU can only interact w/ tensors on GPU\n",
    "# have to send to device, but that takes time\n",
    "# also can't send everything at once since will take up all of GPU\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()  # some may have more than 1 gpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"model-{int(time.time())}\"  # gives dynamic model name \n",
    "    \n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n",
      "[array([[51, 49, 49, ...,  6,  6,  7],\n",
      "       [72, 72, 65, ...,  6,  6,  7],\n",
      "       [59, 72, 80, ...,  7,  7,  8],\n",
      "       ...,\n",
      "       [14, 24, 23, ..., 44, 37, 39],\n",
      "       [80, 26, 38, ..., 38, 35, 38],\n",
      "       [99, 73, 27, ...,  4,  3, 38]], dtype=uint8)\n",
      " array([1., 0.])]\n",
      "[array([[ 35,  47,  85, ..., 105, 105,  97],\n",
      "       [ 59,  59,  79, ...,   9,  20, 100],\n",
      "       [151, 151, 152, ...,  62,  15,  82],\n",
      "       ...,\n",
      "       [ 92,  85,  61, ..., 115, 116, 114],\n",
      "       [ 94,  59, 108, ..., 115, 111, 108],\n",
      "       [ 65,  93, 107, ..., 107, 110, 108]], dtype=uint8)\n",
      " array([0., 1.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "\n",
    "# training_data[i] is the ith row of a feature and a one-hot encoded label\n",
    "# training_data[i][0] is the feature; [i][1] is the label\n",
    "print(len(training_data))\n",
    "print(training_data[0])\n",
    "print(training_data[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(training_data[1][0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
    "X = X / 255.0  # scaling the imagery since pixel values between 0 and 255\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X) * VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22452\n",
      "2494\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100  # if getting memory error, this is easiest to change\n",
    "EPOCHS = 1\n",
    "\n",
    "# tqdm is progress bar\n",
    "def train(net):\n",
    "    \n",
    "    with open(\"model.log\", \"a\") as f:\n",
    "    \n",
    "        for epoch in tqdm(range(EPOCHS)):\n",
    "            # split data starting from 0 to len(), in steps of BATCH_SIZE\n",
    "            for i in tqdm(range(0, len(train_X), BATCH_SIZE), leave=False):\n",
    "                # print(i, i + BATCH_SIZE)\n",
    "                batch_X = train_X[i: i + BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "                batch_y = train_y[i: i + BATCH_SIZE]\n",
    "\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
    "\n",
    "                # print(f\"Acc: {round(float(acc, 2))}   Loss: {round(float(loss), 4)}\"\")\n",
    "                \n",
    "                f.write(f\"{MODEL_NAME}, {round(time.time(), 3)}, in_sample, {round(float(acc), 2)}, {round(float(loss), 4)} \\n\")\n",
    "\n",
    "                # testing purposes\n",
    "                # if i == 5:\n",
    "                #    break\n",
    "                \n",
    "                # don't want to show logging for every feature, just for every X features to plot accuracy and loss over time\n",
    "                if i % 10 == 0:\n",
    "                    val_acc, val_loss = test(size=100)\n",
    "                    f.write(f\"{MODEL_NAME}, {round(time.time(), 3)}, {round(float(acc), 2)}, {round(float(loss), 4)}, {round(float(val_acc), 2)}, {round(float(val_loss), 4)} \\n\")\n",
    "\n",
    "                break\n",
    "            \n",
    "# older less elegant code            \n",
    "#             net.zero_grad()  # zero gradients\n",
    "#             outputs = net(batch_X)\n",
    "            \n",
    "#             # take the argmax of each comparable entry for outputted values vs original batch\n",
    "#             # if match, the ouputtted value is correct\n",
    "#             matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, batch_y)]\n",
    "#             in_sample_acc = matches.count(True) / len(matches)\n",
    "            \n",
    "#             loss = loss_function(outputs, batch_y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()  # does the update\n",
    "\n",
    "#         print(loss)\n",
    "#         print(\"In-sample acc:\", round(in_sample_acc, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(net):\n",
    "#     correct = 0 \n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for i in tqdm(range(len(test_X))):\n",
    "#             # need to pass test_y and test_X to device\n",
    "#             real_class = torch.argmax(test_y[i]).to(device)\n",
    "#             net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]\n",
    "#             predicted_class = torch.argmax(net_out)\n",
    "#             if predicted_class == real_class:\n",
    "#                 correct += 1\n",
    "#             total += 1\n",
    "#     print(\"Accuracy:\", round(correct / total, 3))\n",
    "\n",
    "def test(size=32):\n",
    "    random_start = np.random.randint(len(test_X) - size)\n",
    "    X, y = test_X[random_start: random_start + size], test_y[random_start: random_start + size]\n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50).to(device), y.to(device))\n",
    "    \n",
    "    return val_acc, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train=False):\n",
    "    \n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "        \n",
    "    outputs = net(X)\n",
    "    # take the argmax of each comparable entry for outputted values vs original batch\n",
    "    # if match, the ouputtted value is correct\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True) / len(matches)\n",
    "    loss = loss_function(outputs, y)\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting accuracy loss graph over training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model.log\", \"r\").read().split(\"\\n\")\n",
    "    \n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    \n",
    "    for c in contents:\n",
    "        if model_name in c:\n",
    "            name, timestamp, sample_type, acc, loss = c.split(\",\")\n",
    "            \n",
    "            times.append(timestamp)\n",
    "            accuracies.append(acc)\n",
    "            losses.append(loss)\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax1 = plt.subplot2grid((2, 1), (0, 0))\n",
    "    ax2 = plt.subplot2grid((2, 1), (1, 0), sharex=ax1)\n",
    "    \n",
    "    ax1.plot(times, accuracies, label='in_samp_acc')\n",
    "    ax1.legend(loc=2)\n",
    "    ax2.plot(times, losses, label=\"in_samp_loss\")\n",
    "    ax2.legend(loc=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dceacdbb30e949eca4eed2268ed14eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eaf766cce134930bc229e2fcd344c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'Net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-f94180b75fd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcreate_acc_loss_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-a203495ddf58>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mrandom_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_start\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandom_start\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_start\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandom_start\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'Net'"
     ]
    }
   ],
   "source": [
    "train(net)\n",
    "test(net)\n",
    "create_acc_loss_graph(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
